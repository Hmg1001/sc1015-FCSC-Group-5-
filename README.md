# sc1015-FCSC-Group-5-
# **OVERVIEW:**

This is our SC1015 Mini-Project where we explore on the relationships between the numerous variables and Churn from the CELL2CELL dataset using Machine Learning
1. Data Cleaning
2. EDA
3. Machine Learning Models

# **Dataset:**
Dataset can be found here https://www.kaggle.com/datasets/jpacse/datasets-for-churn-telecom

# **Methodology:**
## Data Cleaning
- Handle invalid, NaN or outlier data
- The boolean values being encoded in the form yes/no_{column name}

## Models (Logstic Regression, Decision Tree and Random Forest)
- Used to determine the more important attributes that will affect churn by comparing the Importance Values.

## Conclusion
In conclusion, our exploration into the complex issue of churn within the telecom industry has revealed multifaceted factors at play. While traditional metrics and basic data provide some insight, they often fall short in accurately predicting and understanding churn. The failure of our models underscores the need to consider external influences, such as competitor promotions and psychological factors, when addressing churn.

1) Competitor company promotions wield significant influence, shaping customer decisions and loyalty. By closely monitoring and strategically responding to competitor offerings, telecom companies can better retain their customer base and mitigate churn.
2) Complex interplay of emotions, perceptions, beliefs, and motivations that influence customers' behavior and decision-making processes. Hence, understanding customers' motivations and preferences through collecting feedbacks, survey results etc will also help to enable companies to tailor their strategies and offerings more effectively to reduce churn.

As we navigate the complexities of churn, it becomes evident that an all rounded approach, incorporating both traditional data analysis and insights from external factors, is essential. By embracing this comprehensive perspective, pherhaps we can create a more well-rounded and better performing model.

## References
- Navlani, A. (2019, December 16). Python logistic regression tutorial with Sklearn & Scikit. DataCamp. https://www.datacamp.com/tutorial/understanding-logistic-regression-python?utm_source=google&utm_medium=paid_search&utm_campaignid=19589720821&utm_adgroupid=157156375191&utm_device=c&utm_keyword=&utm_matchtype=&utm_network=g&utm_adpostion=&utm_creative=684592139660&utm_targetid=aud-299261629614%3Adsa-2218886984100&utm_loc_interest_ms=&utm_loc_physical_ms=9062524&utm_content=&utm_campaign=230119_1-sea~dsa~tofu_2-b2c_3-row-p1_4-prc_5-na_6-na_7-le_8-pdsh-go_9-na_10-na_11-na&gad_source=1&gclid=CjwKCAjw26KxBhBDEiwAu6KXt4hECluCGneSME_FOhwr7TUEBQ5ZkvKVrjn25J3RDqpyq9Tgv4Ec0xoCSgQQAvD_BwE
- Navlani, A. (2023, February 23). Python decision tree classification tutorial: Scikit-Learn Decisiontreeclassifier. DataCamp. https://www.datacamp.com/tutorial/decision-tree-classification-python
- Shafi, A. (2023, February 24). Random Forest classification with Scikit-Learn. DataCamp. https://www.datacamp.com/tutorial/random-forests-classifier-python
- Pamina. (2018, December 14). Telecom churn (cell2cell). Kaggle. https://www.kaggle.com/datasets/jpacse/datasets-for-churn-telecom
